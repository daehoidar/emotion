# 수치예측 & 이진분류

## *선형 회귀

모델에 가장 적합한 일차함수 y = Wx+b를 찾아야 합니다.
y의 값을 변하게 하는 x를 독립 변수라고 하고, x에 따라서 바뀌는 y를 종속 변수라 합니다.

* 단순 선형 회귀의 기본 형태  
▶ y=Wx+b  

머신러닝에서는 W는 가중치, b는 편향이라고 칭합니다. W와 b없이는 y = x라는 항등함수 밖에 없기 때문에 W, b는 꼭 필요합니다.

## *손실 함수, 경사 하강법
### *단순 선형 회귀
앞서 언급한 W, b를 찾기 위해 실제값과 가설로부터 얻은 예측값의 오차를 계산하는 식을 세워서 이 식의 값을 최소화하는 W, b를 찾아 낸다. 이 때의 실제값과 예측값에 대한 오차에 대한 식을 손실 함수라 합니다.

 비용 함수의 식은 단순하게 실제 값과 에측값에 대한 오차를 예측값과 실제값과의 오차를 줄이는 일에도 최적화된 식이어야 합니다.머신러닝, 딥러닝에 다양한 문제들이 있고, 각 문제들에 적합한 비용 함수들이 있는데 회귀 문제에서는 주로 평균 제곱 오차가 사용됩니다.

 실제 값 - 예측값을 한 다음 제곱을 하여 모두 더한다. 그리고 이 오차들의 제곱의 평균을 더합니다.
 
